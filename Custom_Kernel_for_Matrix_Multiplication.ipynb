{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XkFQVpF_zrhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe8ef54-1482-4847-81a4-323a5d18529c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "CPU RAM Free: 12.4 GB\n",
            "GPU 0 ... Mem Free: 15101MB / 15360MB | Utilization   0%\n"
          ]
        }
      ],
      "source": [
        "!pip -q install gputil psutil humanize\n",
        "# Import packages\n",
        "import os,sys,humanize,psutil,GPUtil\n",
        "\n",
        "# Define function\n",
        "def mem_report():\n",
        "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
        "\n",
        "  GPUs = GPUtil.getGPUs()\n",
        "  for i, gpu in enumerate(GPUs):\n",
        "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'\n",
        "    .format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
        "\n",
        "# Execute function\n",
        "mem_report()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbm9GkuB8Y_W",
        "outputId": "e2a66fd9-ba1a-4a77-a56e-3ec0136d3cae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 30 01:37:24 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tesla T4 → Compute Capability 7.5 → Architecture 7.5"
      ],
      "metadata": {
        "id": "VSb3QRb_8fVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TORCH_CUDA_ARCH_LIST'] = \"7.5\""
      ],
      "metadata": {
        "id": "mNs6TnfL8l1d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install python3-pybind11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dWFoh1d4Imi",
        "outputId": "1bd1c5bc-0336-4fc4-c672-f03937dbc3dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libeigen3-dev pybind11-dev python3-numpy\n",
            "Suggested packages:\n",
            "  libeigen3-doc libmpfrc++-dev pybind11-doc python-numpy-doc python3-pytest\n",
            "The following NEW packages will be installed:\n",
            "  libeigen3-dev pybind11-dev python3-numpy python3-pybind11\n",
            "0 upgraded, 4 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,826 kB of archives.\n",
            "After this operation, 29.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pybind11-dev all 2.9.1-2 [146 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-numpy amd64 1:1.21.5-1ubuntu22.04.1 [3,467 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-pybind11 all 2.9.1-2 [156 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libeigen3-dev all 3.4.0-2ubuntu2 [1,056 kB]\n",
            "Fetched 4,826 kB in 1s (4,709 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pybind11-dev.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack .../pybind11-dev_2.9.1-2_all.deb ...\n",
            "Unpacking pybind11-dev (2.9.1-2) ...\n",
            "Selecting previously unselected package python3-numpy.\n",
            "Preparing to unpack .../python3-numpy_1%3a1.21.5-1ubuntu22.04.1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Selecting previously unselected package python3-pybind11.\n",
            "Preparing to unpack .../python3-pybind11_2.9.1-2_all.deb ...\n",
            "Unpacking python3-pybind11 (2.9.1-2) ...\n",
            "Selecting previously unselected package libeigen3-dev.\n",
            "Preparing to unpack .../libeigen3-dev_3.4.0-2ubuntu2_all.deb ...\n",
            "Unpacking libeigen3-dev (3.4.0-2ubuntu2) ...\n",
            "Setting up pybind11-dev (2.9.1-2) ...\n",
            "Setting up libeigen3-dev (3.4.0-2ubuntu2) ...\n",
            "Setting up python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Setting up python3-pybind11 (2.9.1-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkUSTVDcOq-x",
        "outputId": "0d62ae85-6902-4067-a5ee-2a6cc903fddd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/422.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/422.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matmul_kernel.cu\n",
        "#include <torch/extension.h>\n",
        "\n",
        "template <typename T>\n",
        "__global__ void matmul_kernel(const T* A, const T* B, T* C, int M, int N, int K) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < M && col < N) {\n",
        "        T sum = 0;\n",
        "        for (int k = 0; k < K; ++k) {\n",
        "            sum += A[row * K + k] * B[k * N + col];\n",
        "        }\n",
        "        C[row * N + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "void matmul_launcher(torch::Tensor A, torch::Tensor B, torch::Tensor C) {\n",
        "    int M = A.size(0); // Number of rows in A\n",
        "    int K = A.size(1); // Number of columns in A\n",
        "    int N = B.size(1); // Number of columns in B\n",
        "\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 numBlocks((N + 15) / 16, (M + 15) / 16);\n",
        "    matmul_kernel<<<numBlocks, threadsPerBlock>>>(A.data_ptr<T>(), B.data_ptr<T>(), C.data_ptr<T>(), M, N, K);\n",
        "}\n",
        "\n",
        "torch::Tensor matmul_binding(torch::Tensor A, torch::Tensor B) {\n",
        "    TORCH_CHECK(A.dim() == 2 && B.dim() == 2, \"Input matrices must be 2-dimensional\");\n",
        "    TORCH_CHECK(A.size(1) == B.size(0), \"Inner dimensions of matrices must match\");\n",
        "\n",
        "    auto C = torch::zeros({A.size(0), B.size(1)}, A.options()); // Create the result tensor on the same device\n",
        "    AT_DISPATCH_FLOATING_TYPES(A.scalar_type(), \"matmul_launcher\", ([&] {\n",
        "        matmul_launcher<scalar_t>(A, B, C);\n",
        "    }));\n",
        "    return C;\n",
        "}\n",
        "\n",
        "PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n",
        "    m.def(\"matmul\", &matmul_binding, \"Matrix multiplication kernel for dynamically sized matrices\");\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sqWyYJTOWNS",
        "outputId": "b1703b35-5e7b-4cbe-f7ea-72c7d14d4038"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matmul_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.cpp_extension import load\n",
        "\n",
        "matmul_kernel = load(\n",
        "    name=\"matmul_kernel\",\n",
        "    sources=[\"matmul_kernel.cu\"],\n",
        "    extra_cuda_cflags=[\"-O3\"]\n",
        ")"
      ],
      "metadata": {
        "id": "uIlqAlZXPM_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def matmul_cuda(A, B):\n",
        "    \"\"\"\n",
        "    Perform matrix multiplication on CUDA without Python-side dimension handling.\n",
        "    A: (MxK) Tensor\n",
        "    B: (KxN) Tensor\n",
        "    Returns:\n",
        "        C: (MxN) Tensor\n",
        "    \"\"\"\n",
        "    return matmul_kernel.matmul(A, B)\n",
        "\n",
        "# Example usage:\n",
        "A = torch.randn(32, 64, device='cuda')  # MxK\n",
        "B = torch.randn(64, 16, device='cuda')  # KxN\n",
        "C = matmul_cuda(A, B)\n",
        "print(C.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWfQkuZSOjHP",
        "outputId": "945644ad-10b0-47fb-d7b8-4ab351eb5c2d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "A = torch.randn(32, 64, device='cuda')  # MxK\n",
        "B = torch.randn(64, 16, device='cuda')  # KxN\n",
        "\n",
        "start = time.time()\n",
        "C_pytorch = torch.matmul(A, B)\n",
        "print(\"PyTorch Time:\", time.time() - start)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "C = matmul_cuda(A, B)\n",
        "print(\"CUDA Kernel Time:\", time.time() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7q4w1c2Pdr5",
        "outputId": "018ab3b2-b9fa-41a2-c660-4cc2430314f5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Time: 0.10501384735107422\n",
            "CUDA Kernel Time: 0.00020503997802734375\n"
          ]
        }
      ]
    }
  ]
}